=================================
Music Visualizer
------------
Saini Ye & E314 [December 2021]

Credit to:

Mina PECHEUX
Based on the work by Yu-Jie Lin
(Public Domain)
Github: https://gist.github.com/manugarri/1c0fcfe9619b775bb82de0790ccb88da
=================================

LICENSE: CC0 (Public Domain) - see the file in the archive for more info
--------

DISCLAIMERS:
------------
  - all bash scripts use ffmpeg, so you need to install it first if
    you don't have it yet (https://ffmpeg.org/)
  - for now, the project only works with .wav and .mp4 files
  - all scripts and commands except file names WITHOUT their extension
  - the Python script doesn't automatically merge the audio and video
    (see step 4)


TL;DR:
------
A test audio file of some fingers snapping is provided with the scripts to
easily try out the project. Here is the entire process to get a fully finished
generated video:

  0. (optional) Start a virtual environment
  1. Install the Python packages:

      ~$ pip install -r requirements.txt
  
  2. Convert the .mp3 to .wav file (you may skip if you have the .wav file already)

    (1) python3 data_manip.py

    (2) Following the input promp, type in the filename, For example:

        test.mp3

        And the output file will be test.wav in the same directory, it will also gives you 4 graphs: double and single channel fft spectrumand spectrogram

  3. Convert the test audio file, which is mono, to stereo:

      ~$ bash convert_to_stereo.sh test

  4. Create the video from the sound file (may take a while):
    
      ~$ python main.py -m bars -c "#FF7F50" --output test_stereo

      (hints: The input after the -m gives the pattern options: bars, wave, spectrum, rain)
      (hints: The input after the -c gives the color option in hexadecimal format, #FF7F50 is coral)

  5. Merge the video and the audio:

      ~$ bash add_audio_to_video.sh -a test_stereo -v test_stereo

  6. Your final video is now available: it's the "test_stereo_processed.mp4" file 
